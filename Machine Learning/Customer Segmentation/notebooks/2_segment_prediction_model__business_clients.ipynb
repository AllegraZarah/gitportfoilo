{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Client Segment Prediction Model\n",
    "\n",
    "## Objective\n",
    "Develop a predictive model to classify business clients into RFMT-based segments using demographic information collected at sign-up, enabling better engagement and retention strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Data Loading\n",
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as python_random\n",
    "import re\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "# Set environment variables for optimized performance\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '4'  # Improve parallel processing efficiency\n",
    "\n",
    "# Scikit-learn utilities\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, KFold, StratifiedKFold, RepeatedKFold, ShuffleSplit, StratifiedShuffleSplit, GridSearchCV\n",
    ")\n",
    "from sklearn.feature_selection import SelectFromModel, RFECV, RFE\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, PolynomialFeatures, Normalizer\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, f1_score, roc_auc_score, mean_squared_error, accuracy_score, log_loss, classification_report\n",
    ")\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet, RidgeClassifier, Lasso\n",
    "from sklearn.ensemble import (\n",
    "    IsolationForest, RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, \n",
    "    AdaBoostClassifier, VotingClassifier, StackingClassifier\n",
    ")\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from xgboost import XGBRFClassifier, XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Display working directory\n",
    "print(\"Current Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading & Exploration\n",
    "Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labeled corporate client segmentation data\n",
    "labels_data = pd.read_csv(r\"Machine Learning\\Customer Segmentation\\artifacts\\Business_Clients_Clusters.csv\")\n",
    "\n",
    "# Load demographic data of corporate clients\n",
    "demo_data = pd.read_csv(r\"Machine Learning\\Customer Segmentation\\data\\3_business_clients_demographics.csv\")\n",
    "\n",
    "# Make copies for processing\n",
    "labels_data_copy = labels_data.copy()\n",
    "demo_data_copy = demo_data.copy()\n",
    "\n",
    "# Display dataset shapes\n",
    "print(f\"Labels Data Shape: {labels_data.shape}\")\n",
    "print(f\"Demographic Data Shape: {demo_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge demographic data with labeled segmentation dataset\n",
    "data = pd.merge(left=labels_data, right=demo_data, on='cid', how='left')\n",
    "\n",
    "# Display merged dataset shape\n",
    "print(f\"Merged Data Shape: {data.shape}\")\n",
    "\n",
    "# Display first few records\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Missing Values & Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values per column\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values[missing_values > 0])\n",
    "\n",
    "# Check for duplicate client IDs\n",
    "duplicate_counts = data['cid'].duplicated().sum()\n",
    "print(f\"Duplicate Client IDs: {duplicate_counts}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "data.describe(include='all')\n",
    "\n",
    "# Check dataset distribution\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "### **Removing Unnecessary Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display column names\n",
    "data.columns\n",
    "\n",
    "# Retain only columns that do not contain '2'\n",
    "col_without_2 = [col for col in data.columns if '2' not in col]\n",
    "final_data_1 = data[col_without_2]\n",
    "\n",
    "# Selecting relevant columns for analysis\n",
    "final_data = final_data_1[['cid', 'Cluster', 'created', 'account_type', 'is_synced_wb',\n",
    "                           'is_afex_broker', 'is_kyc_complete', 'user_account_type', \n",
    "                           'used_referral_code', 'country', 'region', 'subregion', \n",
    "                           'state', 'rc_number', 'company_website', 'politically_exposed',\n",
    "                           'date_of_incorporation', 'nature_of_business', 'city', \n",
    "                           'political_experience', 'place_of_incorporation']]\n",
    "\n",
    "# Display dataset shape and sample records\n",
    "final_data.shape\n",
    "final_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploartory Data Analysis (EDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values in 'used_referral_code'\n",
    "set(final_data['used_referral_code'])\n",
    "\n",
    "# Uncomment for additional EDA\n",
    "# pd.DataFrame(final_data['nature_of_business'].value_counts().sort_values(ascending=False)).head(30)\n",
    "# final_data['company_website'].count()\n",
    "# final_data[final_data['rc_number'].astype(str).str.startswith('RC')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Engineering**\n",
    "\n",
    "#### Handling Missing & Inconsistent Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'politically_exposed'\n",
    "final_data['politically_exposed'] = final_data['politically_exposed'].fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating New Features\n",
    "\n",
    "**Website Presence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_website_address(x):\n",
    "    pattern = re.compile(r'^(http[s]?://|www)[^\\s]+[.]\\w{2,}[/]?$')\n",
    "    return \"has website\" if re.match(pattern, str(x)) else \"does not have website\"\n",
    "\n",
    "final_data['has_website'] = final_data['company_website'].apply(is_website_address)\n",
    "\n",
    "# Display results\n",
    "final_data[['company_website', 'has_website']].iloc[150:180].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RC Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def referral_null(x):\n",
    "    return 'referred' if str(x).startswith(('COMX', 'comx')) else 'not referred'\n",
    "\n",
    "final_data['is_referred'] = final_data['used_referral_code'].apply(referral_null)\n",
    "\n",
    "# Display results\n",
    "final_data[['used_referral_code', 'is_referred']].head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Company Age Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = pd.to_datetime('now')\n",
    "final_data['age'] = (now - pd.to_datetime(final_data['date_of_incorporation'], errors='coerce')).dt.total_seconds() / (60 * 60 * 24 * 365.25)\n",
    "\n",
    "# Round age values for clarity\n",
    "final_data['age'] = final_data['age'].apply(lambda x: round(x, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datetime Feature Extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_data['created'] = pd.to_datetime(final_data['created'])\n",
    "\n",
    "final_data['created_year'] = final_data['created'].dt.year\n",
    "final_data['created_month'] = final_data['created'].dt.month\n",
    "final_data['created_dayofweek'] = final_data['created'].dt.dayofweek\n",
    "final_data['created_dayofmonth'] = final_data['created'].dt.day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping Unnecessary Columns After Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['used_referral_code', 'subregion', 'city', 'rc_number', 'company_website', \n",
    "           'nature_of_business', 'political_experience', 'date_of_incorporation',\n",
    "           'place_of_incorporation', 'cid']\n",
    "\n",
    "final_processed = final_data.drop(to_drop, axis=1)\n",
    "\n",
    "# Display dataset after dropping\n",
    "final_processed.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "final_processed.info()\n",
    "final_processed.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical, Numeric, and Boolean Columns Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_column = final_processed.select_dtypes(include=['O']).columns.values\n",
    "num_column = final_processed.select_dtypes(include=['float64', 'int64', 'int32', 'float32']).columns.values\n",
    "bool_column = final_processed.select_dtypes(include=['bool']).columns.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in categorical columns with mode\n",
    "for col in cat_column:\n",
    "    final_processed[col] = final_processed[col].fillna(final_processed[col].mode().values[0])\n",
    "\n",
    "# Fill missing values in numerical columns with median\n",
    "for column in num_column:\n",
    "    final_processed[column] = final_processed[column].fillna(final_processed[column].median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Encoding Categorical & Boolean Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Separate 'created' before encoding\n",
    "final_processed_created = final_processed['created']\n",
    "final_processed_others = final_processed.drop('created', axis=1)\n",
    "\n",
    "# Label encode categorical and boolean columns\n",
    "for column in cat_column:\n",
    "    label_e = LabelEncoder()\n",
    "    final_processed_others[column] = label_e.fit_transform(final_processed_others[column])\n",
    "\n",
    "for column in bool_column:\n",
    "    label_e = LabelEncoder()\n",
    "    final_processed_others[column] = label_e.fit_transform(final_processed_others[column])\n",
    "\n",
    "# Merge back 'created' column\n",
    "tot_data = pd.concat([final_processed_created, final_processed_others], axis=1)\n",
    "tot_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splitting Data into Training & Testing Sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify time range for splitting\n",
    "tot_data.created.min(), tot_data.created.max()\n",
    "tot_data.created.sort_values()\n",
    "\n",
    "# Split based on date\n",
    "training_data = tot_data[tot_data.created < '2023-01-01']\n",
    "testing_data = tot_data[tot_data.created >= '2023-01-01']\n",
    "\n",
    "# Drop 'created' column post-split\n",
    "training_data.drop('created', axis=1, inplace=True)\n",
    "testing_data.drop('created', axis=1, inplace=True)\n",
    "\n",
    "# Display dataset shapes\n",
    "training_data.shape, testing_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature & Traget Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = testing_data.drop('Cluster', axis=1)\n",
    "test_target = testing_data['Cluster']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating Train & Validation Sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features & target\n",
    "X = training_data.drop('Cluster', axis=1)\n",
    "y = training_data['Cluster']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Display shapes\n",
    "X.shape, y.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize the features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Distribution Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train).value_counts(normalize=True) * 100\n",
    "pd.DataFrame(y_test).value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modeling with Scaled Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Linear Models**\n",
    "\n",
    "##### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7428571428571429\n",
      "\n",
      "f1 score :::: 0.6691147942367455\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.09      0.15        32\n",
      "           1       0.77      0.97      0.86       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.74       175\n",
      "   macro avg       0.37      0.35      0.33       175\n",
      "weighted avg       0.64      0.74      0.67       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(random_state = 42)\n",
    "model_lr.fit(X_train_scaled,y_train)\n",
    "pred_lr = model_lr.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_lr))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_lr, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7542857142857143\n",
      "\n",
      "f1 score :::: 0.6740563784042044\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.09      0.15        32\n",
      "           1       0.77      0.98      0.86       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.75       175\n",
      "   macro avg       0.40      0.36      0.34       175\n",
      "weighted avg       0.65      0.75      0.67       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_rc = RidgeClassifier(random_state = 42)\n",
    "model_rc.fit(X_train_scaled,y_train)\n",
    "pred_rc = model_rc.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_rc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_rc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_rc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GaussianNaïveBayes (GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.2\n",
      "\n",
      "f1 score :::: 0.10015808303519427\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.97      0.31        32\n",
      "           1       0.80      0.03      0.06       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.20       175\n",
      "   macro avg       0.33      0.33      0.12       175\n",
      "weighted avg       0.63      0.20      0.10       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[ 31   1   0]\n",
      " [127   4   0]\n",
      " [ 12   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_gnb = GaussianNB()\n",
    "model_gnb.fit(X_train_scaled,y_train)\n",
    "pred_gnb = model_gnb.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_gnb))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_gnb, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_gnb))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tree Model**\n",
    "##### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.6514285714285715\n",
      "\n",
      "f1 score :::: 0.6442434404742224\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.38      0.35        32\n",
      "           1       0.77      0.78      0.78       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.37      0.38      0.37       175\n",
      "weighted avg       0.64      0.65      0.64       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_dtc = DecisionTreeClassifier(random_state = 42)\n",
    "model_dtc.fit(X_train_scaled,y_train)\n",
    "pred_dtc = model_dtc.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_dtc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_dtc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_dtc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bagging-Based Models (Parallel Ensemble)**\n",
    "##### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7314285714285714\n",
      "\n",
      "f1 score :::: 0.6939929627023221\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.31      0.34        32\n",
      "           1       0.79      0.90      0.84       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.39      0.40      0.40       175\n",
      "weighted avg       0.66      0.73      0.69       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "model_rfc = RandomForestClassifier(random_state = 42)\n",
    "model_rfc.fit(X_train_scaled,y_train)\n",
    "pred_rfc = model_rfc.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_rfc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_rfc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7371428571428571\n",
      "\n",
      "f1 score :::: 0.6935479543930247\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.28      0.33        32\n",
      "           1       0.78      0.92      0.85       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.74       175\n",
      "   macro avg       0.40      0.40      0.39       175\n",
      "weighted avg       0.66      0.74      0.69       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "model_rfc2 = RandomForestClassifier(n_estimators = 350,random_state = 42)\n",
    "model_rfc2.fit(X_train_scaled,y_train)\n",
    "pred_rfc2 = model_rfc2.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_rfc2))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_rfc2, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_rfc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.6628571428571428\n",
      "\n",
      "f1 score :::: 0.6443984160828511\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.31      0.29        32\n",
      "           1       0.77      0.81      0.79       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.35      0.37      0.36       175\n",
      "weighted avg       0.63      0.66      0.64       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "model_bc = BaggingClassifier(random_state = 42)\n",
    "model_bc.fit(X_train_scaled,y_train)\n",
    "pred_bc = model_bc.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_bc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_bc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_bc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.6857142857142857\n",
      "\n",
      "f1 score :::: 0.6622144942131724\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.34      0.33        32\n",
      "           1       0.78      0.83      0.80       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.36      0.39      0.38       175\n",
      "weighted avg       0.64      0.69      0.66       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "model_bc2 = BaggingClassifier(n_estimators  =7 ,random_state = 42)\n",
    "model_bc2.fit(X_train_scaled,y_train)\n",
    "pred_bc2 = model_bc2.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_bc2))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_bc2, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_bc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7485714285714286\n",
      "\n",
      "f1 score :::: 0.670496644295302\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.09      0.15        32\n",
      "           1       0.77      0.98      0.86       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.75       175\n",
      "   macro avg       0.38      0.36      0.34       175\n",
      "weighted avg       0.64      0.75      0.67       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "\n",
    "model_bc3 = BaggingClassifier(estimator =RidgeClassifier(random_state=  42), n_estimators  =10 ,random_state = 42)\n",
    "model_bc3.fit(X_train_scaled,y_train)\n",
    "pred_bc3 = model_bc3.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_bc3))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_bc3, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_bc3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7085714285714285\n",
      "\n",
      "f1 score :::: 0.6612712914361375\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.19      0.23        32\n",
      "           1       0.77      0.90      0.83       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.35      0.36      0.35       175\n",
      "weighted avg       0.63      0.71      0.66       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_etc = ExtraTreesClassifier(random_state = 42)\n",
    "model_etc.fit(X_train_scaled,y_train)\n",
    "pred_etc = model_etc.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_etc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_etc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_etc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Boosting-Based Models (Sequential Ensemble)**\n",
    "##### GradientBoostingClassifier (GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.68\n",
      "\n",
      "f1 score :::: 0.6558381186765108\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.22      0.26        32\n",
      "           1       0.77      0.85      0.81       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.37      0.36      0.36       175\n",
      "weighted avg       0.64      0.68      0.66       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  7  23   2]\n",
      " [ 12 112   7]\n",
      " [  2  10   0]]\n"
     ]
    }
   ],
   "source": [
    "model_gbc = GradientBoostingClassifier(random_state = 42)\n",
    "model_gbc.fit(X_train_scaled,y_train)\n",
    "pred_gbc = model_gbc.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_gbc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_gbc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_gbc))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_gbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LightGBMClassifier (LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 200\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.592631\n",
      "[LightGBM] [Info] Start training from score -0.297143\n",
      "[LightGBM] [Info] Start training from score -2.924858\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      " Accuracy :::: 0.6914285714285714\n",
      "\n",
      "f1 score :::: 0.6614940773173132\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.28      0.30        32\n",
      "           1       0.77      0.85      0.81       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.36      0.38      0.37       175\n",
      "weighted avg       0.63      0.69      0.66       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  9  23   0]\n",
      " [ 18 112   1]\n",
      " [  2  10   0]]\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "model_lgbmc = LGBMClassifier(random_state = 42,is_unbalance = True)\n",
    "model_lgbmc.fit(X_train_scaled,y_train)\n",
    "pred_lgbmc = model_lgbmc.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_lgbmc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_lgbmc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_lgbmc))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_lgbmc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7485714285714286\n",
      "\n",
      "f1 score :::: 0.6886020590487534\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.19      0.26        32\n",
      "           1       0.78      0.95      0.86       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.75       175\n",
      "   macro avg       0.40      0.38      0.37       175\n",
      "weighted avg       0.66      0.75      0.69       175\n",
      "\n",
      "\n",
      "confusion_matrix ::::\n",
      "  [[  6  26   0]\n",
      " [  6 125   0]\n",
      " [  2  10   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "model_lgbmc2 = LGBMClassifier(num_leaves= 200,\n",
    "          feature_fraction= 0.1,\n",
    "          bagging_freq= 2,\n",
    "          bagging_fraction= 0.475,\n",
    "          min_data_in_leaf= 10,\n",
    "          objective= 'multiclass',\n",
    "          num_class= 3,\n",
    "          max_bin= 255,\n",
    "          max_depth= -1,\n",
    "          learning_rate= 0.1,\n",
    "          scale_pos_weight= 25,\n",
    "          boosting_type= 'gbdt',\n",
    "          bagging_seed= 42,\n",
    "          metric= 'multi_logloss',\n",
    "          verbosity= -1,\n",
    "          random_state= 42)\n",
    "model_lgbmc2.fit(X_train_scaled,y_train)\n",
    "pred_lgbmc2 = model_lgbmc2.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_lgbmc2))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_lgbmc2, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_lgbmc2))\n",
    "print('\\nconfusion_matrix ::::\\n ',confusion_matrix(y_test,pred_lgbmc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7485714285714286\n",
      "\n",
      "f1 score :::: 0.6409337068160597\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        32\n",
      "           1       0.75      1.00      0.86       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.75       175\n",
      "   macro avg       0.25      0.33      0.29       175\n",
      "weighted avg       0.56      0.75      0.64       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  0  32   0]\n",
      " [  0 131   0]\n",
      " [  0  12   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 3 ***\n",
    "\n",
    "model_lgbmc3 = LGBMClassifier(num_leaves= 200,\n",
    "          feature_fraction= 0.2,\n",
    "          bagging_freq= 50,\n",
    "          bagging_fraction= 0.5,\n",
    "          min_data_in_leaf= 40,\n",
    "          objective= 'multiclass',\n",
    "          num_class= 3,\n",
    "          max_bin= 255,\n",
    "          max_depth= -1,\n",
    "          learning_rate= 0.02,\n",
    "          scale_pos_weight= 25,\n",
    "          boosting_type= 'gbdt',\n",
    "          bagging_seed= 11,\n",
    "          metric= 'multi_logloss',\n",
    "          verbosity= -1,\n",
    "          random_state= 42)\n",
    "model_lgbmc3.fit(X_train_scaled,y_train)\n",
    "pred_lgbmc3 = model_lgbmc3.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_lgbmc3))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_lgbmc3, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_lgbmc3))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_lgbmc3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.6971428571428572\n",
      "\n",
      "f1 score :::: 0.6729480580309619\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.25      0.26        32\n",
      "           1       0.78      0.86      0.82       131\n",
      "           2       0.50      0.08      0.14        12\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.52      0.40      0.41       175\n",
      "weighted avg       0.67      0.70      0.67       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  8  24   0]\n",
      " [ 17 113   1]\n",
      " [  4   7   1]]\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "model_catb = CatBoostClassifier(random_state = 42,verbose = False)\n",
    "model_catb.fit(X_train_scaled,y_train)\n",
    "pred_catb = model_catb.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_catb))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_catb, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_catb))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_catb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7085714285714285\n",
      "\n",
      "f1 score :::: 0.6612712914361375\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.19      0.23        32\n",
      "           1       0.77      0.90      0.83       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.35      0.36      0.35       175\n",
      "weighted avg       0.63      0.71      0.66       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  6  26   0]\n",
      " [ 13 118   0]\n",
      " [  2  10   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "model_catb2 = CatBoostClassifier(iterations=100, random_state = 42, learning_rate=0.1, verbose = False, depth=7, class_weights=[1,1,1])\n",
    "model_catb2.fit(X_train_scaled,y_train)\n",
    "pred_catb2 = model_catb2.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_catb2))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_catb2, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_catb2))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_catb2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [09:23:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.72\n",
      "\n",
      "f1 score :::: 0.6445964331678617\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.06      0.10        32\n",
      "           1       0.75      0.95      0.84       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.72       175\n",
      "   macro avg       0.32      0.34      0.31       175\n",
      "weighted avg       0.60      0.72      0.64       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  2  30   0]\n",
      " [  7 124   0]\n",
      " [  1  11   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "model_xgbc = XGBClassifier(random_state = 42,scale_pos_weight = 5)\n",
    "model_xgbc.fit(X_train_scaled,y_train)\n",
    "pred_xgbc = model_xgbc.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_xgbc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_xgbc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_xgbc))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_xgbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [09:23:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7314285714285714\n",
      "\n",
      "f1 score :::: 0.6513058485139022\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.06      0.10        32\n",
      "           1       0.75      0.96      0.85       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.33      0.34      0.32       175\n",
      "weighted avg       0.61      0.73      0.65       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  2  30   0]\n",
      " [  5 126   0]\n",
      " [  1  11   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "model_xgbc2 = XGBClassifier(learning_rate = 0.02,random_state = 42,scale_pos_weight = 8)\n",
    "model_xgbc2.fit(X_train_scaled,y_train)\n",
    "pred_xgbc2 = model_xgbc2.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_xgbc2))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_xgbc2, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_xgbc2))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_xgbc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.72\n",
      "\n",
      "f1 score :::: 0.6445964331678617\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.06      0.10        32\n",
      "           1       0.75      0.95      0.84       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.72       175\n",
      "   macro avg       0.32      0.34      0.31       175\n",
      "weighted avg       0.60      0.72      0.64       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  2  30   0]\n",
      " [  7 124   0]\n",
      " [  1  11   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "\n",
    "model_xgbc3 = XGBClassifier(random_state = 42,)\n",
    "model_xgbc3.fit(X_train_scaled,y_train)\n",
    "pred_xgbc3 = model_xgbc3.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_xgbc3))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_xgbc3, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_xgbc3))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_xgbc3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Stacking-Based Model (Meta-Learning)**\n",
    "##### VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.6685714285714286\n",
      "\n",
      "f1 score :::: 0.6510312813208841\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.34      0.31        32\n",
      "           1       0.78      0.81      0.79       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.35      0.38      0.37       175\n",
      "weighted avg       0.64      0.67      0.65       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[ 11  21   0]\n",
      " [ 25 106   0]\n",
      " [  3   9   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "clf2 = LGBMClassifier(num_leaves= 200,\n",
    "          feature_fraction= 0.1,\n",
    "          bagging_freq= 2,\n",
    "          bagging_fraction= 0.475,\n",
    "          min_data_in_leaf= 10,\n",
    "          objective= 'multiclass',\n",
    "          num_class= 3,\n",
    "          max_bin= 255,\n",
    "          max_depth= -1,\n",
    "          learning_rate= 0.1,\n",
    "          scale_pos_weight= 25,\n",
    "          boosting_type= 'gbdt',\n",
    "          bagging_seed= 42,\n",
    "          metric= 'multi_logloss',#'precision',\n",
    "          verbosity= -1,\n",
    "          random_state= 42)\n",
    "clf3 =  GradientBoostingClassifier(random_state = 42)\n",
    "clf4 = CatBoostClassifier(random_state = 42,verbose = False)\n",
    "# clf5 = XGBClassifier(random_state = 42,scale_pos_weight = 5)\n",
    "model_vc = VotingClassifier(estimators=[ ('gaussian', clf1), ('lgbm', clf2), ('gradient', clf3), ('catboost', clf4),\n",
    "                                            #('xgb', clf5)\n",
    "                                            ], weights = [1,1,1,1], voting='soft')\n",
    "\n",
    "model_vc.fit(X_train_scaled,y_train)\n",
    "pred_vc = model_vc.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_vc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_vc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_vc))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_vc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.2\n",
      "\n",
      "f1 score :::: 0.10015808303519427\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.97      0.31        32\n",
      "           1       0.80      0.03      0.06       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.20       175\n",
      "   macro avg       0.33      0.33      0.12       175\n",
      "weighted avg       0.63      0.20      0.10       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "clf2 =  GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "model_vc2 = VotingClassifier(estimators=[ ('gaussian', clf1), ('gradient', clf2)], weights = [1,1], voting='hard')\n",
    "\n",
    "model_vc2.fit(X_train_scaled,y_train)\n",
    "pred_vc2 = model_vc2.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_vc2))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_vc2, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_vc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.68\n",
      "\n",
      "f1 score :::: 0.6558381186765108\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.22      0.26        32\n",
      "           1       0.77      0.85      0.81       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.68       175\n",
      "   macro avg       0.37      0.36      0.36       175\n",
      "weighted avg       0.64      0.68      0.66       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "clf2 =  GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "model_vc3 = VotingClassifier(estimators=[ ('gaussian', clf1), ('gradient', clf2)], weights = [2,4], voting='hard')\n",
    "\n",
    "model_vc3.fit(X_train_scaled,y_train)\n",
    "pred_vc3 = model_vc3.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_vc3))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_vc3, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_vc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.6\n",
      "\n",
      "f1 score :::: 0.6157539353224001\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.53      0.38        32\n",
      "           1       0.80      0.67      0.73       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.60       175\n",
      "   macro avg       0.36      0.40      0.37       175\n",
      "weighted avg       0.65      0.60      0.62       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "clf2 =  GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "model_vc4 = VotingClassifier(estimators=[ ('gaussian', clf1), ('gradient', clf2)], weights = [2,4], voting='soft')\n",
    "\n",
    "model_vc4.fit(X_train_scaled,y_train)\n",
    "pred_vc4 = model_vc4.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_vc4))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_vc4, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_vc4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.6914285714285714\n",
      "\n",
      "f1 score :::: 0.6631670487785596\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.22      0.27        32\n",
      "           1       0.78      0.87      0.82       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.38      0.36      0.36       175\n",
      "weighted avg       0.64      0.69      0.66       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators = 500,random_state = 42)\n",
    "clf2 =  GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "model_vc5 = VotingClassifier(estimators=[ ('random_forest', clf1), ('gradient', clf2)], weights = [1,4], voting='soft')\n",
    "\n",
    "model_vc5.fit(X_train_scaled,y_train)\n",
    "pred_vc5 = model_vc5.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_vc5))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_vc5, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_vc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.6914285714285714\n",
      "\n",
      "f1 score :::: 0.6587836734693877\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.19      0.24        32\n",
      "           1       0.77      0.88      0.82       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.37      0.36      0.35       175\n",
      "weighted avg       0.64      0.69      0.66       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators = 500,random_state = 42)\n",
    "clf2 = GradientBoostingClassifier(random_state = 42)\n",
    "clf3 = XGBClassifier(random_state = 42)\n",
    "\n",
    "model_vc6 = VotingClassifier(estimators=[ ('random_forest', clf1), ('gradient', clf2), ('xgb', clf3)], weights = [3,50,8], voting='soft')\n",
    "\n",
    "model_vc6.fit(X_train_scaled,y_train)\n",
    "pred_vc6 = model_vc6.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_vc6))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_vc6, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_vc6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.14857142857142858\n",
      "\n",
      "f1 score :::: 0.12144645326692735\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.28      0.31        32\n",
      "           1       1.00      0.04      0.07       131\n",
      "           2       0.08      1.00      0.15        12\n",
      "\n",
      "    accuracy                           0.15       175\n",
      "   macro avg       0.47      0.44      0.18       175\n",
      "weighted avg       0.82      0.15      0.12       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  9   0  23]\n",
      " [ 18   5 108]\n",
      " [  0   0  12]]\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "clf2 = RandomForestClassifier(n_estimators = 500,random_state = 42)\n",
    "clf3 = GradientBoostingClassifier(random_state = 42, loss= 'log_loss', learning_rate = 10.0, n_estimators= 100)\n",
    "model_vc7 = VotingClassifier(estimators=[ ('gau', clf1),('rand', clf2), ('grad', clf3)], weights= [3, 17,30],voting='hard')\n",
    "\n",
    "model_vc7.fit(X_train_scaled,y_train)\n",
    "pred_vc7 = model_vc7.predict(X_test_scaled)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_vc7))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_vc7, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_vc7))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_vc7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test Best Performing Scaled Dataset Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBMClassifier (LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 200\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.592631\n",
      "[LightGBM] [Info] Start training from score -0.297143\n",
      "[LightGBM] [Info] Start training from score -2.924858\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      " Accuracy :::: 0.9198717948717948\n",
      "\n",
      "f1 score :::: 0.8814798167886649\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.92      1.00      0.96       287\n",
      "           2       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.92       312\n",
      "   macro avg       0.31      0.33      0.32       312\n",
      "weighted avg       0.85      0.92      0.88       312\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  0  19   0]\n",
      " [  0 287   0]\n",
      " [  0   6   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_final = LGBMClassifier(random_state = 42,is_unbalance = True)\n",
    "model_final.fit(X_train_scaled,y_train)\n",
    "pred_final = model_final.predict(X_test_scaled)\n",
    "# print('\\n Accuracy ::::', accuracy_score(y_test,pred_final))\n",
    "# print('\\nf1 score ::::',f1_score(y_test,pred_final))\n",
    "# print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_final))\n",
    "# print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_final))\n",
    "\n",
    "test_pred_final = model_final.predict(test_features)\n",
    "print('\\n Accuracy ::::', accuracy_score(test_target,test_pred_final))\n",
    "print('\\nf1 score ::::',f1_score(test_target,test_pred_final, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(test_target,test_pred_final))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(test_target,test_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.09935897435897435\n",
      "\n",
      "f1 score :::: 0.0810901031463827\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      1.00      0.12        19\n",
      "           1       1.00      0.04      0.08       287\n",
      "           2       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.10       312\n",
      "   macro avg       0.35      0.35      0.07       312\n",
      "weighted avg       0.92      0.10      0.08       312\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[ 19   0   0]\n",
      " [275  12   0]\n",
      " [  6   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_finalgnb = GaussianNB()\n",
    "model_finalgnb.fit(X_train_scaled,y_train)\n",
    "pred_finalgnb = model_finalgnb.predict(X_test_scaled)\n",
    "# print('\\n Accuracy ::::', accuracy_score(y_test,pred_finalgnb))\n",
    "# print('\\nf1 score ::::',f1_score(y_test,pred_finalgnb))\n",
    "# print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_finalgnb))\n",
    "# print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_finalgnb))\n",
    "\n",
    "test_pred_finalgnb = model_finalgnb.predict(test_features)\n",
    "print('\\n Accuracy ::::', accuracy_score(test_target,test_pred_finalgnb))\n",
    "print('\\nf1 score ::::',f1_score(test_target,test_pred_finalgnb, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(test_target,test_pred_finalgnb))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(test_target,test_pred_finalgnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modeling with Unscaled Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Linear Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7485714285714286\n",
      "\n",
      "f1 score :::: 0.6430351288056207\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        32\n",
      "           1       0.75      1.00      0.86       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.75       175\n",
      "   macro avg       0.25      0.33      0.29       175\n",
      "weighted avg       0.56      0.75      0.64       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "unscaled_model_lr = LogisticRegression(random_state = 42)\n",
    "unscaled_model_lr.fit(X_train,y_train)\n",
    "pred_lr = unscaled_model_lr.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_lr))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_lr, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7542857142857143\n",
      "\n",
      "f1 score :::: 0.6740563784042044\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.09      0.15        32\n",
      "           1       0.77      0.98      0.86       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.75       175\n",
      "   macro avg       0.40      0.36      0.34       175\n",
      "weighted avg       0.65      0.75      0.67       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "unscaled_model_rc = RidgeClassifier(random_state = 42)\n",
    "unscaled_model_rc.fit(X_train,y_train)\n",
    "pred_rc = unscaled_model_rc.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_rc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_rc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_rc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GaussianNaïveBayes (GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.13714285714285715\n",
      "\n",
      "f1 score :::: 0.13346958414480467\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        32\n",
      "           1       0.86      0.09      0.17       131\n",
      "           2       0.07      1.00      0.14        12\n",
      "\n",
      "    accuracy                           0.14       175\n",
      "   macro avg       0.31      0.36      0.10       175\n",
      "weighted avg       0.65      0.14      0.13       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  0   2  30]\n",
      " [  1  12 118]\n",
      " [  0   0  12]]\n"
     ]
    }
   ],
   "source": [
    "unscaled_model_gnb = GaussianNB()\n",
    "unscaled_model_gnb.fit(X_train,y_train)\n",
    "pred_gnb = unscaled_model_gnb.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_gnb))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_gnb, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_gnb))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tree-Based Model (Single)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.6514285714285715\n",
      "\n",
      "f1 score :::: 0.6461420221002537\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.38      0.36        32\n",
      "           1       0.77      0.78      0.78       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.65       175\n",
      "   macro avg       0.37      0.38      0.38       175\n",
      "weighted avg       0.64      0.65      0.65       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unscaled_model_dtc = DecisionTreeClassifier(random_state = 42)\n",
    "unscaled_model_dtc.fit(X_train,y_train)\n",
    "pred_dtc = unscaled_model_dtc.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_dtc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_dtc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_dtc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bagging-Based Models (Parallel Ensemble)**\n",
    "##### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7542857142857143\n",
      "\n",
      "f1 score :::: 0.7065767735665696\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.28      0.37        32\n",
      "           1       0.78      0.94      0.85       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.75       175\n",
      "   macro avg       0.44      0.41      0.41       175\n",
      "weighted avg       0.68      0.75      0.71       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "unscaled_model_rfc = RandomForestClassifier(random_state = 42)\n",
    "unscaled_model_rfc.fit(X_train,y_train)\n",
    "pred_rfc = unscaled_model_rfc.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_rfc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_rfc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7428571428571429\n",
      "\n",
      "f1 score :::: 0.6960083054200701\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.25      0.31        32\n",
      "           1       0.79      0.93      0.85       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.74       175\n",
      "   macro avg       0.40      0.39      0.39       175\n",
      "weighted avg       0.67      0.74      0.70       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "unscaled_model_rfc2 = RandomForestClassifier(n_estimators = 350,random_state = 42)\n",
    "unscaled_model_rfc2.fit(X_train,y_train)\n",
    "pred_rfc2 = unscaled_model_rfc2.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_rfc2))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_rfc2, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_rfc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.6628571428571428\n",
      "\n",
      "f1 score :::: 0.6409929553840993\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.28      0.27        32\n",
      "           1       0.76      0.82      0.79       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.66       175\n",
      "   macro avg       0.34      0.37      0.35       175\n",
      "weighted avg       0.62      0.66      0.64       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "unscaled_model_bc = BaggingClassifier(random_state = 42)\n",
    "unscaled_model_bc.fit(X_train,y_train)\n",
    "pred_bc = unscaled_model_bc.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_bc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_bc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_bc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.6857142857142857\n",
      "\n",
      "f1 score :::: 0.6656211927150043\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.38      0.35        32\n",
      "           1       0.78      0.82      0.80       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.37      0.40      0.39       175\n",
      "weighted avg       0.65      0.69      0.67       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "unscaled_model_bc2 = BaggingClassifier(n_estimators  =7 ,random_state = 42)\n",
    "unscaled_model_bc2.fit(X_train,y_train)\n",
    "pred_bc2 = unscaled_model_bc2.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_bc2))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_bc2, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_bc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7485714285714286\n",
      "\n",
      "f1 score :::: 0.683191094619666\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.16      0.23        32\n",
      "           1       0.77      0.96      0.86       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.75       175\n",
      "   macro avg       0.40      0.37      0.36       175\n",
      "weighted avg       0.65      0.75      0.68       175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "\n",
    "unscaled_model_bc3 = BaggingClassifier(estimator =RidgeClassifier(random_state=  42), n_estimators  =10 ,random_state = 42)\n",
    "unscaled_model_bc3.fit(X_train,y_train)\n",
    "pred_bc3 = unscaled_model_bc3.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_bc3))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_bc3, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_bc3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7028571428571428\n",
      "\n",
      "f1 score :::: 0.6633858914590571\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.16      0.20        32\n",
      "           1       0.77      0.89      0.83       131\n",
      "           2       0.25      0.08      0.12        12\n",
      "\n",
      "    accuracy                           0.70       175\n",
      "   macro avg       0.43      0.38      0.38       175\n",
      "weighted avg       0.64      0.70      0.66       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unscaled_model_etc = ExtraTreesClassifier(random_state = 42)\n",
    "unscaled_model_etc.fit(X_train,y_train)\n",
    "pred_etc = unscaled_model_etc.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_etc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_etc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_etc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Boosting-Based Models (Sequential Ensemble)**\n",
    "##### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7428571428571429\n",
      "\n",
      "f1 score :::: 0.701978021978022\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.28      0.38        32\n",
      "           1       0.78      0.92      0.85       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.74       175\n",
      "   macro avg       0.45      0.40      0.41       175\n",
      "weighted avg       0.69      0.74      0.70       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  9  22   1]\n",
      " [  7 121   3]\n",
      " [  0  12   0]]\n"
     ]
    }
   ],
   "source": [
    "unscaled_model_gbc = GradientBoostingClassifier(random_state = 42)\n",
    "unscaled_model_gbc.fit(X_train,y_train)\n",
    "pred_gbc = unscaled_model_gbc.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_gbc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_gbc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_gbc))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_gbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LightGBM Classifier (LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 194\n",
      "[LightGBM] [Info] Number of data points in the train set: 354, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.592631\n",
      "[LightGBM] [Info] Start training from score -0.297143\n",
      "[LightGBM] [Info] Start training from score -2.924858\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      " Accuracy :::: 0.72\n",
      "\n",
      "f1 score :::: 0.6799305254016501\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.28      0.32        32\n",
      "           1       0.77      0.89      0.83       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.72       175\n",
      "   macro avg       0.38      0.39      0.38       175\n",
      "weighted avg       0.65      0.72      0.68       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  9  23   0]\n",
      " [ 14 117   0]\n",
      " [  1  11   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "unscaled_model_lgbmc = LGBMClassifier(random_state = 42,is_unbalance = True)\n",
    "unscaled_model_lgbmc.fit(X_train,y_train)\n",
    "pred_lgbmc = unscaled_model_lgbmc.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_lgbmc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_lgbmc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_lgbmc))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_lgbmc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7314285714285714\n",
      "\n",
      "f1 score :::: 0.6583618312189741\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.09      0.14        32\n",
      "           1       0.76      0.95      0.84       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.35      0.35      0.33       175\n",
      "weighted avg       0.62      0.73      0.66       175\n",
      "\n",
      "\n",
      "confusion_matrix ::::\n",
      "  [[  3  29   0]\n",
      " [  6 125   0]\n",
      " [  1  11   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "unscaled_model_lgbmc2 = LGBMClassifier(num_leaves= 200,\n",
    "          feature_fraction= 0.1,\n",
    "          bagging_freq= 2,\n",
    "          bagging_fraction= 0.475,\n",
    "          min_data_in_leaf= 10,\n",
    "          objective= 'multiclass',\n",
    "          num_class= 3,\n",
    "          max_bin= 255,\n",
    "          max_depth= -1,\n",
    "          learning_rate= 0.1,\n",
    "          scale_pos_weight= 25,\n",
    "          boosting_type= 'gbdt',\n",
    "          bagging_seed= 42,\n",
    "          metric= 'multi_logloss',\n",
    "          verbosity= -1,\n",
    "          random_state= 42)\n",
    "unscaled_model_lgbmc2.fit(X_train,y_train)\n",
    "pred_lgbmc2 = unscaled_model_lgbmc2.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_lgbmc2))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_lgbmc2, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_lgbmc2))\n",
    "print('\\nconfusion_matrix ::::\\n ',confusion_matrix(y_test,pred_lgbmc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7485714285714286\n",
      "\n",
      "f1 score :::: 0.6409337068160597\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        32\n",
      "           1       0.75      1.00      0.86       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.75       175\n",
      "   macro avg       0.25      0.33      0.29       175\n",
      "weighted avg       0.56      0.75      0.64       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  0  32   0]\n",
      " [  0 131   0]\n",
      " [  0  12   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 3 ***\n",
    "\n",
    "unscaled_model_lgbmc3 = LGBMClassifier(num_leaves= 200,\n",
    "          feature_fraction= 0.2,\n",
    "          bagging_freq= 50,\n",
    "          bagging_fraction= 0.5,\n",
    "          min_data_in_leaf= 40,\n",
    "          objective= 'multiclass',\n",
    "          num_class= 3,\n",
    "          max_bin= 255,\n",
    "          max_depth= -1,\n",
    "          learning_rate= 0.02,\n",
    "          scale_pos_weight= 25,\n",
    "          boosting_type= 'gbdt',\n",
    "          bagging_seed= 11,\n",
    "          metric= 'multi_logloss',\n",
    "          verbosity= -1,\n",
    "          random_state= 42)\n",
    "unscaled_model_lgbmc3.fit(X_train,y_train)\n",
    "pred_lgbmc3 = unscaled_model_lgbmc3.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_lgbmc3))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_lgbmc3, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_lgbmc3))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_lgbmc3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7085714285714285\n",
      "\n",
      "f1 score :::: 0.6842707743869034\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.28      0.29        32\n",
      "           1       0.79      0.87      0.83       131\n",
      "           2       1.00      0.08      0.15        12\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.70      0.41      0.42       175\n",
      "weighted avg       0.72      0.71      0.68       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  9  23   0]\n",
      " [ 17 114   0]\n",
      " [  4   7   1]]\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "unscaled_model_catb = CatBoostClassifier(random_state = 42,verbose = False)\n",
    "unscaled_model_catb.fit(X_train,y_train)\n",
    "pred_catb = unscaled_model_catb.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_catb))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_catb, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_catb))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_catb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7142857142857143\n",
      "\n",
      "f1 score :::: 0.6651348651348652\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.19      0.23        32\n",
      "           1       0.77      0.91      0.83       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.36      0.37      0.35       175\n",
      "weighted avg       0.63      0.71      0.67       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  6  26   0]\n",
      " [ 12 119   0]\n",
      " [  2  10   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "unscaled_model_catb2 = CatBoostClassifier(iterations=100, random_state = 42, learning_rate=0.1, verbose = False, depth=7, class_weights=[1,1,1])\n",
    "unscaled_model_catb2.fit(X_train,y_train)\n",
    "pred_catb2 = unscaled_model_catb2.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_catb2))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_catb2, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_catb2))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_catb2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [09:23:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7257142857142858\n",
      "\n",
      "f1 score :::: 0.6896045038705138\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.34      0.38        32\n",
      "           1       0.78      0.89      0.83       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.40      0.41      0.40       175\n",
      "weighted avg       0.66      0.73      0.69       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[ 11  21   0]\n",
      " [ 15 116   0]\n",
      " [  0  12   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "unscaled_model_xgbc = XGBClassifier(random_state = 42,scale_pos_weight = 5)\n",
    "unscaled_model_xgbc.fit(X_train,y_train)\n",
    "pred_xgbc = unscaled_model_xgbc.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_xgbc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_xgbc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_xgbc))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_xgbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [09:23:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7428571428571429\n",
      "\n",
      "f1 score :::: 0.702555761213005\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.31      0.37        32\n",
      "           1       0.79      0.92      0.85       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.74       175\n",
      "   macro avg       0.41      0.41      0.41       175\n",
      "weighted avg       0.67      0.74      0.70       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[ 10  22   0]\n",
      " [ 10 120   1]\n",
      " [  2  10   0]]\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "unscaled_model_xgbc2 = XGBClassifier(learning_rate = 0.02,random_state = 42,scale_pos_weight = 8)\n",
    "unscaled_model_xgbc2.fit(X_train,y_train)\n",
    "pred_xgbc2 = unscaled_model_xgbc2.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_xgbc2))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_xgbc2, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_xgbc2))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_xgbc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7257142857142858\n",
      "\n",
      "f1 score :::: 0.6896045038705138\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.34      0.38        32\n",
      "           1       0.78      0.89      0.83       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.40      0.41      0.40       175\n",
      "weighted avg       0.66      0.73      0.69       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[ 11  21   0]\n",
      " [ 15 116   0]\n",
      " [  0  12   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "\n",
    "unscaled_model_xgbc3 = XGBClassifier(random_state = 42,)\n",
    "unscaled_model_xgbc3.fit(X_train,y_train)\n",
    "pred_xgbc3 = unscaled_model_xgbc3.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_xgbc3))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_xgbc3, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_xgbc3))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_xgbc3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Stacking-Based Model (Meta-Learning)**\n",
    "##### VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.13714285714285715\n",
      "\n",
      "f1 score :::: 0.13346958414480467\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        32\n",
      "           1       0.86      0.09      0.17       131\n",
      "           2       0.07      1.00      0.14        12\n",
      "\n",
      "    accuracy                           0.14       175\n",
      "   macro avg       0.31      0.36      0.10       175\n",
      "weighted avg       0.65      0.14      0.13       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  0   2  30]\n",
      " [  1  12 118]\n",
      " [  0   0  12]]\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "clf1 = unscaled_model_gnb\n",
    "clf2 = unscaled_model_lgbmc3\n",
    "clf3 = unscaled_model_gbc\n",
    "\n",
    "\n",
    "unscaled_model_vc = VotingClassifier(estimators=[ ('gaussian', clf1), ('lgbm', clf2), ('gradientboosting', clf3)], weights = [4,1,2], voting='hard')\n",
    "\n",
    "unscaled_model_vc.fit(X_train,y_train)\n",
    "pred_vc = unscaled_model_vc.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_vc))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_vc, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_vc))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_vc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7371428571428571\n",
      "\n",
      "f1 score :::: 0.6975479515114316\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.28      0.37        32\n",
      "           1       0.78      0.92      0.84       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.74       175\n",
      "   macro avg       0.44      0.40      0.40       175\n",
      "weighted avg       0.68      0.74      0.70       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  0   2  30]\n",
      " [  1  12 118]\n",
      " [  0   0  12]]\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "clf2 =  GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "unscaled_model_vc2 = VotingClassifier(estimators=[ ('gaussian', clf1), ('gradient', clf2)], weights = [1,1], voting='hard')\n",
    "\n",
    "unscaled_model_vc2.fit(X_train,y_train)\n",
    "pred_vc2 = unscaled_model_vc2.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_vc2))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_vc2, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_vc2))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_vc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7428571428571429\n",
      "\n",
      "f1 score :::: 0.701978021978022\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.28      0.38        32\n",
      "           1       0.78      0.92      0.85       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.74       175\n",
      "   macro avg       0.45      0.40      0.41       175\n",
      "weighted avg       0.69      0.74      0.70       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  0   2  30]\n",
      " [  1  12 118]\n",
      " [  0   0  12]]\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "clf2 =  GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "unscaled_model_vc3 = VotingClassifier(estimators=[ ('gaussian', clf1), ('gradient', clf2)], weights = [2,4], voting='hard')\n",
    "\n",
    "unscaled_model_vc3.fit(X_train,y_train)\n",
    "pred_vc3 = unscaled_model_vc3.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_vc3))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_vc3, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_vc3))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_vc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.72\n",
      "\n",
      "f1 score :::: 0.7019555927943025\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.22      0.32        32\n",
      "           1       0.80      0.88      0.84       131\n",
      "           2       0.21      0.33      0.26        12\n",
      "\n",
      "    accuracy                           0.72       175\n",
      "   macro avg       0.53      0.48      0.47       175\n",
      "weighted avg       0.72      0.72      0.70       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  0   2  30]\n",
      " [  1  12 118]\n",
      " [  0   0  12]]\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "clf2 =  GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "unscaled_model_vc4 = VotingClassifier(estimators=[ ('gaussian', clf1), ('gradient', clf2)], weights = [2,4], voting='soft')\n",
    "\n",
    "unscaled_model_vc4.fit(X_train,y_train)\n",
    "pred_vc4 = unscaled_model_vc4.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_vc4))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_vc4, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_vc4))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_vc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7542857142857143\n",
      "\n",
      "f1 score :::: 0.7160862155388471\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.34      0.44        32\n",
      "           1       0.79      0.92      0.85       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.75       175\n",
      "   macro avg       0.47      0.42      0.43       175\n",
      "weighted avg       0.70      0.75      0.72       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  0   2  30]\n",
      " [  1  12 118]\n",
      " [  0   0  12]]\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators = 500,random_state = 42)\n",
    "clf2 =  GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "unscaled_model_vc5 = VotingClassifier(estimators=[ ('random_forest', clf1), ('gradient', clf2)], weights = [1,4], voting='soft')\n",
    "\n",
    "unscaled_model_vc5.fit(X_train,y_train)\n",
    "pred_vc5 = unscaled_model_vc5.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_vc5))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_vc5, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_vc5))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_vc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7485714285714286\n",
      "\n",
      "f1 score :::: 0.711475125261372\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.34      0.43        32\n",
      "           1       0.78      0.92      0.85       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.75       175\n",
      "   macro avg       0.45      0.42      0.43       175\n",
      "weighted avg       0.69      0.75      0.71       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  0   2  30]\n",
      " [  1  12 118]\n",
      " [  0   0  12]]\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "\n",
    "clf1 = RandomForestClassifier(n_estimators = 500,random_state = 42)\n",
    "clf2 = GradientBoostingClassifier(random_state = 42)\n",
    "clf3 = XGBClassifier(random_state = 42)\n",
    "\n",
    "unscaled_model_vc6 = VotingClassifier(estimators=[ ('random_forest', clf1), ('gradient', clf2), ('xgb', clf3)], weights = [3,50,8], voting='soft')\n",
    "\n",
    "unscaled_model_vc6.fit(X_train,y_train)\n",
    "pred_vc6 = unscaled_model_vc6.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_vc6))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_vc6, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_vc6))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_vc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.14857142857142858\n",
      "\n",
      "f1 score :::: 0.12234023582907964\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.28      0.31        32\n",
      "           1       1.00      0.04      0.07       131\n",
      "           2       0.08      1.00      0.15        12\n",
      "\n",
      "    accuracy                           0.15       175\n",
      "   macro avg       0.48      0.44      0.18       175\n",
      "weighted avg       0.82      0.15      0.12       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  9   0  23]\n",
      " [ 17   5 109]\n",
      " [  0   0  12]]\n",
      "\\confusion_matrix ::::\n",
      "  [[  0   2  30]\n",
      " [  1  12 118]\n",
      " [  0   0  12]]\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "clf2 = RandomForestClassifier(n_estimators = 500,random_state = 42)\n",
    "clf3 = GradientBoostingClassifier(random_state = 42, loss= 'log_loss', learning_rate = 10.0, n_estimators= 100)\n",
    "unscaled_model_vc7 = VotingClassifier(estimators=[ ('gau', clf1),('rand', clf2), ('grad', clf3)], weights= [3, 17,30],voting='hard')\n",
    "\n",
    "unscaled_model_vc7.fit(X_train,y_train)\n",
    "pred_vc7 = unscaled_model_vc7.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_vc7))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_vc7, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_vc7))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_vc7))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_vc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test Best Performing Unscaled Dataset Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7428571428571429\n",
      "\n",
      "f1 score :::: 0.701978021978022\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.28      0.38        32\n",
      "           1       0.78      0.92      0.85       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.74       175\n",
      "   macro avg       0.45      0.40      0.41       175\n",
      "weighted avg       0.69      0.74      0.70       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  9  22   1]\n",
      " [  7 121   3]\n",
      " [  0  12   0]]\n",
      "\n",
      " Accuracy :::: 0.6634615384615384\n",
      "\n",
      "f1 score :::: 0.7446395496549553\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.11      0.09        19\n",
      "           1       0.92      0.71      0.80       287\n",
      "           2       0.02      0.17      0.03         6\n",
      "\n",
      "    accuracy                           0.66       312\n",
      "   macro avg       0.34      0.33      0.31       312\n",
      "weighted avg       0.85      0.66      0.74       312\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  2  12   5]\n",
      " [ 25 204  58]\n",
      " [  0   5   1]]\n"
     ]
    }
   ],
   "source": [
    "unscaled_model_final = unscaled_model_gbc\n",
    "unscaled_model_final.fit(X_train,y_train)\n",
    "pred_final = unscaled_model_final.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_final))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_final, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_final))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_final))\n",
    "\n",
    "test_pred_final = unscaled_model_final.predict(test_features)\n",
    "print('\\n Accuracy ::::', accuracy_score(test_target,test_pred_final))\n",
    "print('\\nf1 score ::::',f1_score(test_target,test_pred_final, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(test_target,test_pred_final))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(test_target,test_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [09:23:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy :::: 0.7257142857142858\n",
      "\n",
      "f1 score :::: 0.6896045038705138\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.34      0.38        32\n",
      "           1       0.78      0.89      0.83       131\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.73       175\n",
      "   macro avg       0.40      0.41      0.40       175\n",
      "weighted avg       0.66      0.73      0.69       175\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[ 11  21   0]\n",
      " [ 15 116   0]\n",
      " [  0  12   0]]\n",
      "\n",
      " Accuracy :::: 0.7532051282051282\n",
      "\n",
      "f1 score :::: 0.8020052596975673\n",
      "\n",
      "classification_report ::::\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.26      0.13        19\n",
      "           1       0.93      0.80      0.86       287\n",
      "           2       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.75       312\n",
      "   macro avg       0.34      0.35      0.33       312\n",
      "weighted avg       0.87      0.75      0.80       312\n",
      "\n",
      "\\confusion_matrix ::::\n",
      "  [[  5  12   2]\n",
      " [ 49 230   8]\n",
      " [  2   4   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\OluwatomisinSoetan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "unscaled_model_finalgnb = unscaled_model_xgbc\n",
    "unscaled_model_finalgnb.fit(X_train,y_train)\n",
    "pred_finalgnb = unscaled_model_finalgnb.predict(X_test)\n",
    "print('\\n Accuracy ::::', accuracy_score(y_test,pred_finalgnb))\n",
    "print('\\nf1 score ::::',f1_score(y_test,pred_finalgnb, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(y_test,pred_finalgnb))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(y_test,pred_finalgnb))\n",
    "\n",
    "test_pred_finalgnb = unscaled_model_finalgnb.predict(test_features)\n",
    "print('\\n Accuracy ::::', accuracy_score(test_target,test_pred_finalgnb))\n",
    "print('\\nf1 score ::::',f1_score(test_target,test_pred_finalgnb, average='weighted'))\n",
    "print('\\nclassification_report ::::\\n ',classification_report(test_target,test_pred_finalgnb))\n",
    "print('\\confusion_matrix ::::\\n ',confusion_matrix(test_target,test_pred_finalgnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model\n",
    "\n",
    "The GradientBoosting Classifier model, trained on the unscaled dataset, was ultimately selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(unscaled_model_final, open('models/business_clients_rfmt_cluster_model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
